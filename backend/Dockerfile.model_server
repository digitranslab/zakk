FROM python:3.11.7-slim-bookworm

LABEL com.danswer.maintainer="founders@digi-trans.org"
LABEL com.danswer.description="This image is for the Zakk model server which runs all of the \
AI models for Zakk. This container and all the code is MIT Licensed and free for all to use. \
You can find it at https://hub.docker.com/r/zakk/zakk-model-server. For more details, \
visit https://github.com/digitranslab/zakk."

# Default ZAKK_VERSION, typically overriden during builds by GitHub Actions.
ARG ZAKK_VERSION=0.0.0-dev
ENV ZAKK_VERSION=${ZAKK_VERSION} \
    DANSWER_RUNNING_IN_DOCKER="true"

RUN echo "ZAKK_VERSION: ${ZAKK_VERSION}"

COPY ./requirements/model_server.txt /tmp/requirements.txt
RUN pip install --no-cache-dir --upgrade \
        --retries 5 \
        --timeout 30 \
        -r /tmp/requirements.txt

# Clean up package manager cache
RUN apt-get remove -y --allow-remove-essential perl-base && \ 
    apt-get autoremove -y && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Pre-downloading models for setups with limited egress
# Download tokenizers and models in a single layer to reduce image size
RUN python -c "import os; \
from transformers import AutoTokenizer; \
print('Downloading tokenizers...'); \
AutoTokenizer.from_pretrained('distilbert-base-uncased'); \
AutoTokenizer.from_pretrained('mixedbread-ai/mxbai-rerank-xsmall-v1'); \
print('Tokenizers downloaded successfully'); \
from huggingface_hub import snapshot_download; \
print('Downloading digitranslab models...'); \
try: \
    snapshot_download('digitranslab/hybrid-intent-token-classifier', local_files_only=False); \
    print('Successfully cached hybrid-intent-token-classifier'); \
except Exception as e: \
    print(f'hybrid-intent-token-classifier not available, will use fallback: {e}'); \
try: \
    snapshot_download('digitranslab/information-content-model', local_files_only=False); \
    print('Successfully cached information-content-model'); \
except Exception as e: \
    print(f'information-content-model not available, will use fallback: {e}'); \
print('Downloading other models...'); \
snapshot_download('nomic-ai/nomic-embed-text-v1'); \
snapshot_download('mixedbread-ai/mxbai-rerank-xsmall-v1'); \
from sentence_transformers import SentenceTransformer; \
SentenceTransformer(model_name_or_path='nomic-ai/nomic-embed-text-v1', trust_remote_code=True); \
print('All models downloaded successfully'); \
# Clean up any temporary files \
import shutil; \
cache_dir = '/root/.cache/huggingface'; \
if os.path.exists(cache_dir): \
    for item in os.listdir(cache_dir): \
        item_path = os.path.join(cache_dir, item); \
        if os.path.isdir(item_path) and item.startswith('tmp'): \
            shutil.rmtree(item_path); \
print('Cleanup completed')"

# In case the user has volumes mounted to /root/.cache/huggingface that they've downloaded while
# running Zakk, don't overwrite it with the built in cache folder
RUN mv /root/.cache/huggingface /root/.cache/temp_huggingface

WORKDIR /app

# Utils used by model server
COPY ./zakk/utils/logger.py /app/zakk/utils/logger.py
COPY ./zakk/utils/middleware.py /app/zakk/utils/middleware.py

# Place to fetch version information
COPY ./zakk/__init__.py /app/zakk/__init__.py

# Shared between Zakk Backend and Model Server
COPY ./shared_configs /app/shared_configs

# Model Server main code
COPY ./model_server /app/model_server

ENV PYTHONPATH=/app

CMD ["uvicorn", "model_server.main:app", "--host", "0.0.0.0", "--port", "9000"]
